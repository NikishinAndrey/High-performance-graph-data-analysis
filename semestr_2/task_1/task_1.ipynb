{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPut4qt2v77v"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graphs(total=100, min_verts=4, max_verts=100, random_seed=0):\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "\n",
        "    graph_list = []\n",
        "    target_list = []\n",
        "\n",
        "    for idx in range(total):\n",
        "        node_count = random.randint(min_verts, max_verts)\n",
        "        if idx < total // 2:\n",
        "            G = nx.path_graph(node_count)\n",
        "            target = 0\n",
        "        else:\n",
        "            G = nx.cycle_graph(node_count)\n",
        "            target = 1\n",
        "\n",
        "        graph_list.append(G)\n",
        "        target_list.append(target)\n",
        "\n",
        "    return graph_list, target_list\n",
        "\n",
        "def compute_shortest_path_histogram(graph, max_path=1):\n",
        "    path_lengths = []\n",
        "    for start_node in graph.nodes():\n",
        "        paths = nx.single_source_shortest_path_length(graph, start_node, cutoff=max_path)\n",
        "        for end_node, length in paths.items():\n",
        "            if 1 <= length <= max_path and start_node < end_node:\n",
        "                path_lengths.append(length)\n",
        "\n",
        "    histogram = np.zeros(max_path)\n",
        "    for length in path_lengths:\n",
        "        histogram[length-1] += 1\n",
        "    return histogram\n",
        "\n",
        "def compute_kernel(train_data, test_data, max_path=1):\n",
        "    features_train = np.array([compute_shortest_path_histogram(g, max_path=max_path) for g in train_data])\n",
        "    features_test = np.array([compute_shortest_path_histogram(g, max_path=max_path) for g in test_data])\n",
        "\n",
        "    K_tr = np.dot(features_train, features_train.T)\n",
        "    K_te = np.dot(features_test, features_train.T)\n",
        "    return K_tr, K_te"
      ],
      "metadata": {
        "id": "FXlMSWIiyRJt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphs, labels = create_graphs(100)\n",
        "\n",
        "for i in range(0, 100, 25):\n",
        "    g = graphs[i]\n",
        "    print(f'LOG: Graph #{i+1}, class: {labels[i]}, nodes: {g.number_of_nodes()}, edges: {g.number_of_edges()}')\n",
        "\n",
        "graph_data, targets = create_graphs(total=400, min_verts=10, max_verts=80, random_seed=0)\n",
        "train_graphs, test_graphs, y_tr, y_te = train_test_split(graph_data, targets, test_size=0.1, stratify=targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USFX9XAu7hyg",
        "outputId": "27f5b812-95b4-4744-f1f1-a487b9308505"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOG: Graph #1, class: 0, nodes: 53, edges: 52\n",
            "LOG: Graph #26, class: 0, nodes: 16, edges: 15\n",
            "LOG: Graph #51, class: 1, nodes: 94, edges: 94\n",
            "LOG: Graph #76, class: 1, nodes: 42, edges: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_tr1, K_te1 = compute_kernel(train_graphs, test_graphs)\n",
        "K_tr2, K_te2 = compute_kernel(train_graphs, test_graphs, max_path=2)\n",
        "\n",
        "print('--- Single feature ---')\n",
        "clf = SVC(kernel='precomputed', random_state=42)\n",
        "clf.fit(K_tr1, y_tr)\n",
        "preds = clf.predict(K_te1)\n",
        "print(f\"Accuracy: {accuracy_score(y_te, preds):.3f}\")\n",
        "print(f\"Precision: {precision_score(y_te, preds):.3f}\")\n",
        "print(f\"Recall: {recall_score(y_te, preds):.3f}\")\n",
        "\n",
        "print('\\n--- Two features ---')\n",
        "clf = SVC(kernel='precomputed', random_state=42)\n",
        "clf.fit(K_tr2, y_tr)\n",
        "preds = clf.predict(K_te2)\n",
        "print(f\"Accuracy: {accuracy_score(y_te, preds):.3f}\")\n",
        "print(f\"Precision: {precision_score(y_te, preds):.3f}\")\n",
        "print(f\"Recall: {recall_score(y_te, preds):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzBooLX97G6H",
        "outputId": "a7ab353e-0b90-42f0-fd30-2110682c869e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Single feature ---\n",
            "Accuracy: 0.475\n",
            "Precision: 0.478\n",
            "Recall: 0.550\n",
            "\n",
            "--- Two features ---\n",
            "Accuracy: 1.000\n",
            "Precision: 1.000\n",
            "Recall: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. С одной фичей (max_path=1) метод показывает низкую эффективность (Accuracy: 0.475), что близко к случайному угадыванию\n",
        "\n",
        "2. С двумя фичами (max_path=2) достигается идеальная классификация (Accuracy: 1.000)\n",
        "\n",
        "3. Это свидетельствует о том, что гистограмма распределения путей длины 2 содержит достаточную информацию для идеального разделения цепочек и циклов (простая задача)"
      ],
      "metadata": {
        "id": "IPOuGRzuMi83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weisfeiler-Lehman Kernel"
      ],
      "metadata": {
        "id": "wyvfqysiMCyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_wl_features(graph_list, num_hops):\n",
        "    all_graph_labels = []\n",
        "    for G in graph_list:\n",
        "        labels = {n: str(G.degree(n)) for n in G.nodes()}\n",
        "        all_graph_labels.append(labels)\n",
        "\n",
        "    unique_labels = set()\n",
        "    graph_histories = []\n",
        "\n",
        "    for idx, G in enumerate(graph_list):\n",
        "        current_labels = all_graph_labels[idx].copy()\n",
        "        history = []\n",
        "\n",
        "        for hop in range(num_hops + 1):\n",
        "            freq_count = Counter(current_labels.values())\n",
        "            history.append(freq_count.copy())\n",
        "            unique_labels.update(freq_count.keys())\n",
        "\n",
        "            if hop < num_hops:\n",
        "                new_labels = {}\n",
        "                for node in G.nodes():\n",
        "                    neighbor_labels = sorted([current_labels[neigh] for neigh in G.neighbors(node)])\n",
        "                    new_label = current_labels[node] + \"_\" + \"_\".join(neighbor_labels)\n",
        "                    new_labels[node] = new_label\n",
        "                current_labels = new_labels\n",
        "\n",
        "        graph_histories.append(history)\n",
        "\n",
        "    label_mapping = {lab: i for i, lab in enumerate(sorted(unique_labels))}\n",
        "\n",
        "    feature_vectors = []\n",
        "    for history in graph_histories:\n",
        "        combined_hist = Counter()\n",
        "        for hist in history:\n",
        "            combined_hist.update(hist)\n",
        "\n",
        "        vec = np.zeros(len(label_mapping))\n",
        "        for label, count in combined_hist.items():\n",
        "            vec[label_mapping[label]] = count\n",
        "        feature_vectors.append(vec)\n",
        "\n",
        "    return feature_vectors, label_mapping\n",
        "\n",
        "def compute_wl_kernel(train_graphs, test_graphs, num_hops=2):\n",
        "    train_features, label_map = extract_wl_features(train_graphs, num_hops)\n",
        "\n",
        "    def get_test_features(test_graphs):\n",
        "        test_labels = []\n",
        "        for G in test_graphs:\n",
        "            labels = {n: str(G.degree(n)) for n in G.nodes()}\n",
        "            test_labels.append(labels)\n",
        "\n",
        "        test_histories = []\n",
        "\n",
        "        for idx, G in enumerate(test_graphs):\n",
        "            current_labels = test_labels[idx].copy()\n",
        "            history = []\n",
        "\n",
        "            for hop in range(num_hops + 1):\n",
        "                freq_count = Counter(current_labels.values())\n",
        "                history.append(freq_count.copy())\n",
        "\n",
        "                if hop < num_hops:\n",
        "                    new_labels = {}\n",
        "                    for node in G.nodes():\n",
        "                        neighbor_labels = sorted([current_labels[neigh] for neigh in G.neighbors(node)])\n",
        "                        new_label = current_labels[node] + \"_\" + \"_\".join(neighbor_labels)\n",
        "                        new_labels[node] = new_label\n",
        "                    current_labels = new_labels\n",
        "\n",
        "            test_histories.append(history)\n",
        "\n",
        "        test_vectors = []\n",
        "        for history in test_histories:\n",
        "            combined_hist = Counter()\n",
        "            for hist in history:\n",
        "                combined_hist.update(hist)\n",
        "\n",
        "            vec = np.zeros(len(label_map))\n",
        "            for label, count in combined_hist.items():\n",
        "                if label in label_map:\n",
        "                    vec[label_map[label]] = count\n",
        "            test_vectors.append(vec)\n",
        "\n",
        "        return test_vectors\n",
        "\n",
        "    test_features = get_test_features(test_graphs)\n",
        "    train_features = np.array(train_features)\n",
        "    test_features = np.array(test_features)\n",
        "\n",
        "    K_train = train_features @ train_features.T\n",
        "    K_test = test_features @ train_features.T\n",
        "\n",
        "    return K_train, K_test"
      ],
      "metadata": {
        "id": "sYClnUCH_79K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-- 0 hops --')\n",
        "K_train, K_test = compute_wl_kernel(train_graphs, test_graphs, num_hops=0)\n",
        "\n",
        "model = SVC(kernel='precomputed', random_state=0)\n",
        "model.fit(K_train, y_tr)\n",
        "preds = model.predict(K_test)\n",
        "print(f\"WL Accuracy: {accuracy_score(y_te, preds):.3f}\")\n",
        "print(f\"WL Precision: {precision_score(y_te, preds):.3f}\")\n",
        "print(f\"WL Recall: {recall_score(y_te, preds):.3f}\")\n",
        "\n",
        "print('\\n-- 1 hop --')\n",
        "K_train1, K_test1 = compute_wl_kernel(train_graphs, test_graphs, num_hops=1)\n",
        "\n",
        "model = SVC(kernel='precomputed', random_state=0)\n",
        "model.fit(K_train1, y_tr)\n",
        "preds = model.predict(K_test1)\n",
        "print(f\"WL Accuracy: {accuracy_score(y_te, preds):.3f}\")\n",
        "print(f\"WL Precision: {precision_score(y_te, preds):.3f}\")\n",
        "print(f\"WL Recall: {recall_score(y_te, preds):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhtOANtGGPOn",
        "outputId": "49498a6d-d25e-4eeb-c635-4ffa212fd31a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- 0 hops --\n",
            "WL Accuracy: 1.000\n",
            "WL Precision: 1.000\n",
            "WL Recall: 1.000\n",
            "\n",
            "-- 1 hop --\n",
            "WL Accuracy: 1.000\n",
            "WL Precision: 1.000\n",
            "WL Recall: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Уже на 0 итерациях (только по степеням вершин) достигается идеальная классификация\n",
        "\n",
        "2. Добавление 1 хопа не улучшает результат, так как он уже максимален\n",
        "\n",
        "3. Это указывает на то, что распределение степеней вершин достаточно для различения цепочек и циклов"
      ],
      "metadata": {
        "id": "5ggPamOH9Azp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Общие выводы"
      ],
      "metadata": {
        "id": "qFKZP82t9GBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Оба метода способны достигать 100% точности на данной задаче (**очень простая задача классификации**)\n",
        "\n",
        "- WL метод более эффективен - требует только начальных меток (степеней вершин)\n",
        "\n",
        "- Метод кратчайших путей требует анализа путей длины 2 для достижения максимальной точности\n",
        "\n",
        "- WL метод демонстрирует лучшую \"разрешающую способность\" на простых структурах графов"
      ],
      "metadata": {
        "id": "M-CeQJQO9Irl"
      }
    }
  ]
}